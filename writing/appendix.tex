\section{Experimental Materials}
\subsection{Bot-Check Trial}
The names used in the bot-check trials were: 
\begin{itemize}
\item Male names: James, John, Robert, Michael, William, David, Richard, Joseph, Thomas, Charles 
\item Female names: Mary, Patricia, Jennifer, Linda, Elizabeth, Barbara, Susan, Jessica, Sarah, Margaret. 
\end{itemize}
This trial view was developed and provided by Elisa Kreiss. 
\subsection{E1 Exclusion Criteria}
In the Sentence Rating Experiment (E2), data from \rlgetvariable{myvars-rating.csv}{nExcludedTotal} participants was excluded. \rlgetvariable{myvars-rating.csv}{nNonEN} participants indicated a native language other than English. Data from \rlgetvariable{myvars-rating.csv}{nFailedWarmUp} subjects was excluded due to failed warm-up trials. This means, participants provided a lower rating of the sentence “The chair is blue” than the sentence “The chair is yellow” on the chair warm-up trial; it was also counted as a fail if participants rated the sentence “The basketball is green” higher than the sentence “The basketball is orange”, or if the rating of the sentence “The basketball is orange” received a rating of less than 50 on the basketball trial.

Furthermore, data from \rlgetvariable{myvars-rating.csv}{nFailedMains} participants were excluded who provided the same ratings within 5 points for one syntactic condition on every trial (one of the sentences on every trial), or those who provided the same ratings of the two sentences on every trial. 
However, choosing exclusion criteria based on participants’ performance in the main trials might have been an overly restrictive or biasing criterion. So an exploratory analysis was conducted on the full dataset, where participants were only excluded based on their performance in the practice trials. 
This exploratory analysis revealed results qualitatively and quantitatively very similar to results from the main preregistered analysis reported in the main work: participants dispreferred sentences with a subordinate predicate noun, compared to sentences with basic-level subordinate nouns, but did not show any preferences in the subject-noun condition (syntax-by-noun interaction: $\beta = \rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{syntax:NP}{Estimate}{2}  [\rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{syntax:NP}{l.95..CI}{2}, \rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{syntax:NP}{u.95..CI}{2}]$). They also overall preferred the subject-N syntax ($\beta = \rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{syntax}{Estimate}{2} [\rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{syntax}{l.95..CI}{2}, \rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{syntax}{u.95..CI}{2}] $), as well as basic-level nouns ($\beta = \rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{NP}{Estimate}{2} [\rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{NP}{l.95..CI}{2},\rlgetnum{expt1_brm_full_exploratory.csv}{Rowname}{NP}{u.95..CI}{2}] $). 

%\subsection{E2, E3 Response Classification}
%The following free-production responses were excluded from analysis in Experiment 2 (Noun Production): "last", "oak", "finch", "duck", "lavender", "salmon", "goldfinch", "dahlia", "poetry", "one", "lablador", "geony".

%The following provided responses (corrected for misspellings, capitalization and number) were classified as subordinate: "goldfish", "hummingbird", "canary", "doberman", "sunflower", "swordfish", "sparrow", "tuna", "peony", "chihuahua", "daisy",  "clownfish", "Great Dane", "goose", "bonsai", "pug", "dandelion", "swan", "eagle", "redwood", "blue swordfish", "eagle that is landing", "red clownfish", "Dandelion with seeds", "sequoia", "redwood tree", "peony flower".

%The following provided responses (also corrected) were classified as basic-level: "birds", "dogs", "great dog", "fish", "fishes", "flowers", "trees", "animal", "plants", "weeds".

%The following free-production responses were excluded from analysis in Experiment 3 (Comparison Class Inference): "that man is big", "that's small boy", "that is big one", "that's a small doberman",
%"that bird compare small", "that boy is small", "me is big", "but some one small", "that pug small",
%"you are small", "beauty for fish", "yes", "aim", "growth", "honest", "medicine", "heathy", "dogs name", "trees name", "big", "tall", "small", "cute", "good", "bushes", "why it in land", "what is this flower", "fish nose", "labrador".

%The following provided responses (corrected for misspellings, capitalization and number) were classified as subordinate: "chihuahuas", "bonsai", "pugs", "great danes", "sunflowers", "dobermen", "swordfish", "dandelions", "goldfish", "eagles", "redwoods", "hummingbirds", "sequoias", "bonsai trees", "redwood trees", "other swordfish", "the other sunflowers".

%The following provided responses (also corrected corrected) were classified as basic-level: "birds", "dogs", "fish", "flowers", "birds in the sky", "big dogs", "things", "objects", "dogs", "dogs that we see", "fish that we see", "birds that we see", "flower", "trees", "animal", "the other birds", "the other dogs", "weeds", "small flowers", "dog", "large dogs", "giant trees", "breeds", "plant", "variety of dogs", "long trees".
\section{Refpred-RSA Model Alternatives}
The main proposed reference-predication RSA model assumes a speaker utility function wherein the speaker chooses an utterance such that it optimally communicates a two-dimensional state of the world (i.e., the referent and its size):
\begin{equation*}
%\label{model1}
U_{S_1} (u; r; s; cc; C) = log \: L_0 (s, r \mid u, C, cc) 
\end{equation*}
However, based on previous models addressing multiple potential questions under discussion, there are other conceivable representations of the speaker utility \parencite[cf.][]{kao2014nonliteral, yoon2016talking}. For instance, another more complex option is to consider a QUD-based model wherein the speaker chooses utterances specifically communicating reference or predication only, or both goals, inspired by \textcite{kao2014nonliteral}. In that case, the speaker-utility is defined with respect to a certain QUD she has in mind: 
\begin{equation*}
U_{S_1} (u; r; s; cc; C; QUD) = log \: L_0(QUD(s, r) \mid u, C, cc)
\end{equation*} 
where $QUD(.)$ projects the state of the world onto the subspace relevant for the particular question under discussion. That is, if the QUD is reference, the literal listener returns a distribution over referents, marginalizing over possible properties. The opposite happens when the QUD is predication. When the QUD is to communicate both aspects, $L_0$ returns a two-dimensional distribution over referents and properties. The latter possibility is equivalent to the main proposed model (Eq.~\ref{model1}). The $L_1$ would then jointly reasons about the intended meaning and the intended QUD: 
\begin{equation*}
P_{L_1} (r, s, cc \mid u, C) \propto \sum_{QUD} P_{S_1} (u, cc \mid s, r, C, QUD) \; P(r, s \mid C, cc_{r\_sub}) \; P(QUD)
\end{equation*} 

Yet another possibility is to follow the idea proposed by \textcite{yoon2016talking}, representing the speaker as trying to simulataneously achieve a combination of the two informational goals (reference and predication) weighted by a free parameter $\phi$ representing referential weight of the sentence:
\begin{equation*}
U_{S_1} (u; r; s; cc; C; \phi) = log(\phi \: L_0(r \mid C) + (1 - \phi) \: L_0(s \mid cc))
\end{equation*} 
To compute the utility for one goal, the distribution returned by $L_0$ is marginalized over the other aspect of the state of the world (equivalently to the QUD-based model). The pragmatic listener then also reasons about the value of $\phi$:
\begin{equation*}
P_{L_1} (r, s, cc, \phi \mid u, C) \propto P_{S_1} (u, cc \mid s, r, C, \phi) \; P(r, s \mid C, cc_{r\_sub}) \; P(\phi)
\end{equation*} 

These are also conceivable representations of reasoning about informational goals. Although the speaker utility proposed in the main model in Section \ref{refpred-rsa} posits a priori that both goals of reference and predication are relevant for any situation, it has clear advantages. First, this model has the simplest, most intuitive structure, avoiding the use of additional layers of inference or free parameters. Second, it implements the reference-predication trade-off hypothesis in a more elegant way: It explains the qualitative inference pattern observed empirically simply based on explaining away alternative states of the world and potential utterances they could have been described by, especially by shifting the noun position, avoiding architectures wherein the speaker would explicitly be biased to use the noun in a specific position to convey a particular informational goal. Positing that interlocutors pursue both informational goals also seems to be a reasonable assumption, given the fundamental nature of reference necessarily underlying predication. Therefore, it is argued that the main proposed model is a more suitable reference-predication hypothesis formalization, but further possible speaker utility representations are left to future research. 