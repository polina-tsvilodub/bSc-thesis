# Comparison Class Inference Experiment Analysis

``` {r libraries, message=FALSE, warnings=FALSE}
library(tidyverse)
library(tidyboot)
library(brms)
library(ggsignif)
library(lmerTest)
```

``` {r data}
# read data
d_infer <- read_csv('./../data/E3_cc_inference/results_30_prereg-cc-inf.csv')

```

``` {r filter}
# exclude participants who report difficulties
d_infer %>%
  select(submission_id, comments, problems) %>%
  distinct() %>%
  View()
d_infer_woGlitches <- subset(d_infer, !(submission_id %in% c(1438, 1515)))

# exclude data from non-native English speakers and those where the language information is missing
d_infer_woGlitches %>% distinct(languages)
d_infer_Native <- d_infer_woGlitches %>%
  filter(grepl("en", languages, ignore.case = T)) %>%
  select(
    submission_id, trial_name, trial_number, target_size, item, botresponse, response,
    condition, pic, pic_spec, ref_spec, attempts
  )

# participants who do not get the comparison class warmup right
d_infer_cc_warmup <- d_infer_Native %>%
  filter(trial_name == "comp_class_warmup") %>%
  group_by(submission_id) %>%
  count() %>%
  filter(n > 4)

# exclude participants who need more than 4 attempts per warmup
d_infer_warmup <- d_infer_Native %>%
  filter((trial_name == "warmup1") | (trial_name == "warmup2")) %>%
  group_by(submission_id) %>%
  filter(attempts > 4)

d_infer_filt1 <- anti_join(d_infer_Native, d_infer_warmup, by = c("submission_id"))
d_infer_filt1 <- anti_join(d_infer_filt1, d_infer_cc_warmup, by = c("submission_id"))
```

``` {r csv vars}
# write a csv with subject exclusion stats for TeX
myvars <- list()

myvars["nSubj"] <- (d_infer %>% distinct(submission_id) %>% count() %>% .$n) - 2 # one extra participant was collected, excluded below
myvars["nExcludedTotal"] <- ((d_infer %>% distinct(submission_id) %>% count() %>% .$n)) -
  (d_infer_filt1 %>% distinct(submission_id) %>% count() %>% .$n)
myvars["nBugs"] <- 0 # subject excluded due to glitches
myvars["nNonEN"] <- (d_infer_woGlitches %>% distinct(submission_id) %>% count() %>% .$n) -
  (d_infer_Native %>% distinct(submission_id) %>% count() %>% .$n)
myvars["nFailedWarmUp"] <- (d_infer_warmup %>% distinct(submission_id) %>% count() %>% .$n %>% sum())
myvars["nFailedCCWarmUp"] <- d_infer_cc_warmup %>%
  distinct(submission_id) %>%
  count() %>%
  .$n %>%
  sum()
# myvars["nFailedMains"] = d_catch_main_counts %>% distinct(submission_id) %>% count() %>% .$n

myvars <- as_tibble(myvars)
# write_csv(myvars, path = "../writing/R4Tex/myvars-infer.csv", col_names = T)
```



``` {r categorization}
d_infer_main <- d_infer_filt1 %>%
  filter((trial_name == "custom_main_text1") |
    (trial_name == "custom_main_text2")) %>%
  filter(submission_id != 1548) %>%
  filter(submission_id != 1549) %>%
  mutate(
    context = factor(pic_spec,
      levels = c(0, 1),
      labels = c(
        "basic",
        "subordinate"
      )
    ),
    NP = ifelse(ref_spec == 2, "one",
      ifelse(ref_spec == 1, "subordinate", "basic")
    ),
    condition = ifelse(condition == 0, "prenominal", "predicative")
  ) %>%
  select(
    submission_id, trial_number, context, item, response, condition,
    pic, target_size, NP
  )

# categorize responses
d_infer_main %>%
  distinct(response) %>%
  View()
# exclude invalid responses
d_infer_valid <- d_infer_main %>% subset(., !(tolower(response) %in% c(
  "that man is big", "that's small boy", "that is big one", "that's a small doberman",
  "that bird compare small", "that boy is small", "me is big", "but some one small", "that pug small",
  "you are small", "beauty for fish", "yes", "aim", "growth", "honest", "medicine", "heathy", "dogs name", "trees name",
  "big", "tall", "small", "cute", "good", "bushes",
  "why it in land", "what is this flower", "fish nose", "labrador"
)))

d_infer_main_responseCat <- d_infer_valid %>%
  rowwise() %>%
  mutate(
    response_cat =
      ifelse( # do be extended dependent on responses provided
        tolower(response) %in% c(
          "birds", "bird", "dogs", "fish", "flowers", "birds in the sky", "big dogs", "fower", "tress", "things", "objects", "dogs.", "dogd",
          "burds", "dogs that we see", "fish that we see", "birds that we see",
          "flower", "trees", "tree", "animal", "the other birds", "the other dogs", "digs", "treees", "weeds", "small flowers", "fishs",
          "fishes", "dog", "large dogs", "giant trees", "breeds", "plant", "variety of dogs", "long trees"
        ), "basic", "subordinate"
      ),

    response_num = ifelse(response_cat == "basic", 1, 0),
    response_label = "basic"
  )
d_infer_main_superordinate <- d_infer_main_responseCat %>%
  filter(tolower(response) %in% c("things", "objects", "animal", "weeds", "plant"))
```


``` {r proportions plot}
# plot
bar.width = 0.8
d_infer_main_responseCat %>%  
  group_by( context, NP, condition) %>%
  tidyboot_mean(column = response_num) -> d_infer_main_responseCat.bs

annotation_df <- data.frame(context = c("Basic-Level Context","Subordinate-Level Context"),
                            start = c("Subject N\n(That N is big)", "Subject N\n(That N is big)"),
                            finish = c("Predicate N\n(That's a big N)", "Predicate N\n(That's a big N)"),
                            y=c(1, 0.75),
                            label = c("1", "1"))

d_infer_main_responseCat.bs %>%
  ungroup() %>%
  mutate(condition = factor(condition, levels = c( "predicative", "prenominal"),
                            labels = c(  "Subject N\n(That N is big)", "Predicate N\n(That's a big N)")),
         context = factor(context, levels = c("basic", "subordinate"),
                          labels = c("Basic-Level Context","Subordinate-Level Context")),
         Noun = factor(NP, levels = c("basic", "one", "subordinate"),
                     labels = c("basic", '"one"', "subordinate"))) %>%
  ggplot(., aes(x=condition, y = mean, fill = Noun, ymin = ci_lower, ymax = ci_upper)) +
  geom_col(position = position_dodge(bar.width), width = bar.width, alpha = 0.5, color= 'black',
            color = 'black', size = 1) +
  geom_linerange(position = position_dodge(bar.width), size = 1) +
  ggthemes::theme_few()+
  xlab("") +
  theme(#legend.position = c(0.92, 0.65),  
    legend.text = element_text(size = 9),
        legend.title = element_text(size = 9), 
        legend.key.size = unit(0.5,"line"))+
  scale_y_continuous(limits = c(0, 1.3),breaks = c(0, 0.5, 1))+
  #ylim(0, 1.1) +
  #scale_fill_grey() +
  ylab("Proportion of basic-level responses") +
  #ggtitle("Experiment 3: Comparison Class Inference")+
  geom_signif(comparisons = list(c("Subject N\n(That N is big)", "Predicate N\n(That's a big N)")),
              tip_length = 0.01) +
 # geom_signif(data = annotation_df, aes(xmin = start, xmax = finish, annotations = label, y_position = y),
  #            manual = T) +
  geom_signif(y_position=c(1.05, 1.05), xmin=c(0.73, 1.75), xmax=c(1.25, 2.25),
              annotation=c("2", "2"), tip_length=0.01) +
  geom_signif(y_position=c(1.15, 1.15), xmin=c(0.73, 1.75), xmax=c(0.95, 1.95),
              annotation=c("3", "3"), tip_length=0.01) +
  geom_signif(y_position=c(1.2, 1.2), xmin=c(1, 2), xmax=c(1.25, 2.25),
              annotation=c("4", "4"), tip_length=0.01) +
  #geom_signif(y_position=c(1.28, 1.28), xmin=c(0.73, 1.75), xmax=c(1.25, 2.25),
   #           annotation=c("5", "5"), tip_length=0.01) +
  facet_grid(~context)  

#ggsave("../writing/images/expt3-cc-inference-wSigLines.pdf", width = 7, height = 4.5)
```

### Cogsci stats

``` {r}

# SUM CODING  
d_infer_main_responseCat2 <- d_infer_main_responseCat %>%
  ungroup() %>%
  mutate(NP_fac = factor(as.character(NP)),
         NP_num = as.numeric(NP_fac)) %>%
  mutate(syntax_contr = ifelse(condition == "predicative", 0.5, -0.5), # contrast coded
         context_sub = ifelse(context == "subordinate", 0.5,-0.5)) %>%
  rowwise() %>%
  # ONE IS THE REFERENCE LEVEL, SUB AND BASIC ARE EACH COMPARED TO THE MEAN
  mutate(NP_subVone = case_when(NP == "one" ~ -1L, # baseline
                        NP == "subordinate" ~ 1L,  # target
                        TRUE      ~ 0L), # anything else
        NP_basicVone = case_when(NP == "one" ~ -1L, # baseline
                        NP == "basic" ~  1L, # target
                        TRUE      ~ 0L),
        syntax_sum = ifelse(condition == "predicative", -1L, 1L),
        context_sum = ifelse(context == "basic", 1L, -1L))

d_infer_main_responseCat2 %>%
  select(condition, syntax_sum, context, context_sum, NP, NP_subVone, NP_basicVone) %>%
  View()
```

#### Sum coded Bayesian models (reported)

``` {r brm model}
# COGSCI REVISIONS: THE SUM CODING IS FIXED TO 'ONE' AS REFERENCE LEVEL, MODELS AND POSTERIOR CONTRASTS ADJUSTED ACCORDINGLY  

unique(d_infer_main_responseCat2$context_sum)
unique(d_infer_main_responseCat2$NP_subVone)
unique(d_infer_main_responseCat2$NP_basicVone)
unique(d_infer_main_responseCat2$syntax_sum)

# Bayesian full model
# significant effect of sub NP and context
lm.b.infer.fit.by.target <- brm(response_num ~ syntax_sum * (NP_subVone + NP_basicVone) * context_sum +
                        (1 + syntax_sum  + NP_subVone + NP_basicVone + context_sum  || submission_id) +
                        (1 + syntax_sum * (NP_subVone + NP_basicVone) * context_sum  || pic),
                      data = d_infer_main_responseCat2,
                      family = "bernoulli",
                      iter = 3000,
                      cores = 4, chains = 4,
                      control = list(adapt_delta = 0.98)) # otherwise there are divergent chains
summary(lm.b.infer.fit.by.target)
```


``` {r}
write_csv(data.frame(summary(lm.b.infer.fit.by.target)[["fixed"]]) %>%
           mutate(Rowname = row.names(.)),
        path = "./../writing/R4Tex/expt3_full_brm_revised2.csv")
```

```{r}
# get posterior samples 
coda = brms::posterior_samples(lm.b.infer.fit.by.target)
antilogit = function(x) 1 / (1 + exp(-x))

# get respective contrasts 
lm.b.infer3way.by.target.fit.samples <- data.frame(
  basic_v_mean = coda[,"b_NP_basicVone"],
  sub_v_mean = coda[,"b_NP_subVone"],
  syntax_sub_v_mean = coda[, "b_syntax_sum:NP_subVone"],
  syntax_basic_v_mean = coda[, "b_syntax_sum:NP_basicVone"],
  context_sub_v_mean = coda[, "b_NP_subVone:context_sum"],
  context_basic_v_mean = coda[, "b_NP_basicVone:context_sum"],
  syntax_context_sub_v_mean = coda[, "b_syntax_sum:NP_subVone:context_sum"],
  syntax_context_basic_v_mean = coda[, "b_syntax_sum:NP_basicVone:context_sum"]
) %>%
  mutate(
    one_v_mean = -sub_v_mean - basic_v_mean,
    sub_v_one = 2 * sub_v_mean + basic_v_mean,
    sub_v_basic = sub_v_mean - basic_v_mean,
    basic_v_sub = basic_v_mean - sub_v_mean,
    basic_v_one = 2* basic_v_mean + sub_v_mean,
    syntax_sub_v_one = 2 *syntax_sub_v_mean + syntax_basic_v_mean,
    syntax_sub_v_basic = syntax_sub_v_mean - syntax_basic_v_mean,
    syntax_basic_v_sub = syntax_basic_v_mean - syntax_sub_v_mean,
    syntax_basic_v_one = 2 * syntax_basic_v_mean + syntax_sub_v_mean,
    syntax_one_v_mean = -syntax_sub_v_mean - syntax_basic_v_mean,
    context_one_v_mean = -context_sub_v_mean - context_basic_v_mean,  
    context_syntax_sub_v_one = 2 *syntax_context_sub_v_mean +
      syntax_context_basic_v_mean,
    context_syntax_sub_v_basic = syntax_context_sub_v_mean -
      syntax_context_basic_v_mean,
    context_syntax_basic_v_one = 2 * syntax_context_basic_v_mean +
      syntax_context_sub_v_mean,
    sub_context_basic_v_one = 
     )

lm.b.infer3way.by.target.fit.samples %>%
  gather(key, val) %>%
  ggplot(., aes( x= val))+
  geom_histogram()+
  facet_wrap(~key)

```

``` {r}
lm.b.infer3way.by.target.fit.samples %>% 
  gather(key, val) %>% 
  group_by(key) %>%
  summarize(
    '|95%' = quantile(val, probs = c(0.025, 0.975))[[1]],
    'mean'  = mean(val),
    'u95%' = quantile(val, probs = c(0.025, 0.975))[[2]],
    prob_gt_0 = mean(val > 0)*100,
    prob_lt_0 = mean(val < 0)*100
  ) -> lm.b.infer3way.full.contrasts

```

``` {r}
write_csv(data.frame(lm.b.infer3way.full.contrasts) %>% 
            mutate(Rowname = key), 
          path = "./../../writing/R_results_TeX/expt3_3way_full_contrasts_wProbs.csv")
```

#### Two-way + context main effect models

``` {r}
# SUM CODED 
lm.b.infer.fit.two.way2.sum <- brm(response_num ~ syntax_sum + NP_subVone + NP_basicVone + context_sum  +
                        syntax_sum:NP_subVone + syntax_sum:NP_basicVone +
                        (1 + syntax_sum + NP_subVone + NP_basicVone + context_sum || submission_id) +
                        (1 + syntax_sum + NP_subVone + NP_basicVone + context_sum  +
                        syntax_sum:NP_subVone + syntax_sum:NP_basicVone || item),
                      data = d_infer_main_responseCat2,
                      family = "bernoulli",
                      iter = 2000,
                      cores = 4, chains = 4,
                      control = list(adapt_delta = 0.95))

lm.b.infer.fit.two.way2.sum.summary <- summary(lm.b.infer.fit.two.way2.sum)
```


``` {r}
write_csv(data.frame(lm.b.infer.fit.two.way2.sum.summary[["fixed"]]) %>%
            mutate(Rowname = row.names(.)),
          path = "./../writing/R4Tex/expt3_2_way_full_brm_revised2.csv")
```

``` {r}
# get posterior samples 
coda2way = brms::posterior_samples(lm.b.infer.fit.two.way2.sum)

# get respective contrasts 
lm.b.infer.2way.fit.samples <- data.frame(
  sub_v_mean = coda2way[, "b_NP_subVone"],
  basic_v_mean = coda2way[, "b_NP_basicVone"],
  syntax_sub_v_mean = coda2way[, "b_syntax_sum:NP_subVone"],
  syntax_basic_v_mean = coda2way[, "b_syntax_sum:NP_basicVone"]
) %>%
  mutate(sub_v_one = 2 *sub_v_mean + basic_v_mean,
         sub_v_basic = sub_v_mean - basic_v_mean,
         basic_v_sub = basic_v_mean - sub_v_mean,
         basic_v_one = 2 * basic_v_mean + sub_v_mean,
         syntax_sub_v_one = 2 *syntax_sub_v_mean + syntax_basic_v_mean,
         syntax_sub_v_basic = syntax_sub_v_mean - syntax_basic_v_mean,
         syntax_basic_v_sub = syntax_basic_v_mean - syntax_sub_v_mean,
         syntax_basic_v_one = 2 * syntax_basic_v_mean + syntax_sub_v_mean )


lm.b.infer.2way.fit.samples %>%
  gather(key, val) %>%
  ggplot(., aes( x= val))+
  geom_histogram()+
  facet_wrap(~key)

```

``` {r}

lm.b.infer.2way.fit.samples %>% 
  gather(key, val) %>% 
  group_by(key) %>%
  summarize(
    '|95%' = quantile(val, probs = c(0.025, 0.975))[[1]],
    'mean'  = mean(val),
    'u95%' = quantile(val, probs = c(0.025, 0.975))[[2]],
    prob_gt_0 = mean(val > 0)*100,
    prob_lt_0 = mean(val < 0)*100
  ) -> lm.b.infer2way.full.contrasts
```

``` {r}
write_csv(
  data.frame(lm.b.infer2way.full.contrasts) %>% 
    mutate(Rowname = key), 
          path = "./../writing/R4Tex/expt3_2way_full_contrasts_wProbs.csv"
)
```

## Stats on data subsets

``` {r}
# secondary analysis
# subsetting the data by context condition
d_infer_contextBasic <- d_infer_main_responseCat2 %>%
  filter(context == "basic")
d_infer_contextSub <- d_infer_main_responseCat2 %>%
  filter(context == "subordinate")

# sum-code

# bayesian models of separate contexts
# basic context
b.context.basic <- brm(response_num ~ syntax_sum + NP_basicVone + NP_subVone  +
                        syntax_sum:NP_basicVone + syntax_sum:NP_subVone +
                        (1 + syntax_sum + NP_basicVone + NP_subVone +
                        syntax_contr:NP_basic + syntax_contr:NP_sub || submission_id) +
                        (1 + syntax_contr + NP_basic + NP_sub +
                        syntax_contr:NP_basic + syntax_contr:NP_sub || item),
                      data = d_infer_contextBasic,
                      family = "bernoulli",
                      iter = 1000,
                      chains = 3,
                      cores = 3)
summary(b.context.basic)

# post cogsci stats
b.context.basic.posterior_samples <- posterior_samples(b.context.basic)
mean(b.context.basic.posterior_samples$`b_syntax_contr:NP_sub` > 0)
mean(b.context.basic.posterior_samples$b_NP_basic - b.context.basic.posterior_samples$b_NP_sub > 0  )
mean(b.context.basic.posterior_samples$b_NP_basic - b.context.basic.posterior_samples$b_NP_sub)
quantile(b.context.basic.posterior_samples$b_NP_basic - b.context.basic.posterior_samples$b_NP_sub, probs = c(0.025, 0.975))

# sub context
b.context.sub <- brm(response_num ~ syntax_sum + NP_basicVone + NP_subVone +
                        syntax_sum:NP_basicVone + syntax_sum:NP_subVone +
                        (1 + syntax_sum + NP_basicVone + NP_subVone  || submission_id) +
                        (1 + syntax_sum + NP_basicVone + NP_subVone +
                        syntax_sum:NP_basicVone + syntax_sum:NP_subVone || item),
                        data = d_infer_contextSub,
                      family = "bernoulli",
                     chains = 4,
                     iter = 3000,
                     cores = 4,
                     control = list(adapt_delta = 0.95))

summary(b.context.sub) -> b.context.sub.summary
# post cogsci stats
b.context.sub.posterior_samples <- posterior_samples(b.context.sub)

mean(b.context.sub.posterior_samples$`b_syntax_contr:NP_sub` > 0)
mean(b.context.sub.posterior_samples$b_NP_basic - b.context.sub.posterior_samples$b_NP_sub > 0  )
mean(b.context.sub.posterior_samples$b_NP_basic - b.context.sub.posterior_samples$b_NP_sub)
quantile(b.context.sub.posterior_samples$b_NP_basic - b.context.sub.posterior_samples$b_NP_sub, probs = c(0.025, 0.975))

# basic N vs one
mean(2*b.context.sub.posterior_samples$b_NP_basic - b.context.sub.posterior_samples$b_NP_sub > 0  )

b.context.sub.posterior_estimates <- data.frame(
  sub_v_mean = b.context.sub.posterior_samples[, "b_NP_subVone"],
  basic_v_mean = b.context.sub.posterior_samples[, "b_NP_basicVone"],
  syntax_sub_v_mean = b.context.sub.posterior_samples[, "b_syntax_sum:NP_subVone"],
  syntax_basic_v_mean = b.context.sub.posterior_samples[, "b_syntax_sum:NP_basicVone"]
) %>%
  mutate(sub_v_one = 2 *sub_v_mean + basic_v_mean,
         sub_v_basic = sub_v_mean - basic_v_mean,
         basic_v_sub = basic_v_mean - sub_v_mean,
         basic_v_one = 2 * basic_v_mean + sub_v_mean)


b.context.sub.posterior_estimates %>% 
  gather(key, val) %>% 
  group_by(key) %>%
  summarize(
    '|95%' = quantile(val, probs = c(0.025, 0.975))[[1]],
    'mean'  = mean(val),
    'u95%' = quantile(val, probs = c(0.025, 0.975))[[2]],
    prob_gt_0 = mean(val > 0)*100,
    prob_lt_0 = mean(val < 0)*100
  ) -> b.context.sub.posterior_estimates.summary

write_csv(data.frame(b.context.sub.posterior_estimates.summary) %>% 
            mutate(Rowname = key), 
          path = "./../writing/R4Tex/expt3_subContext.csv")

```
